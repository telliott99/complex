\documentclass[11pt, oneside]{article} 
\usepackage{geometry}
\geometry{letterpaper} 
\usepackage{graphicx}
	
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{parskip}
\usepackage{color}
\usepackage{hyperref}

\graphicspath{{/Users/telliott/Github/figures/}}

\title{Taylor series}
\date{}

\begin{document}
\maketitle
\Large

%[my-super-duper-separator]

\subsection*{power series}

All analytic functions can be expanded as power series around a fixed point $z_0$.  Churchill says (sect. 44):

\begin{quote}Suppose that a function $f$ is analytic [i.e. has a derivative] throughout an open disk $|z - z_0| < R_0$, centered at $z_0$ and with radius $R_0$.  Then, at each point in that disk, $f(z)$ has the series representation\end{quote}

\[ f(z) = \sum_{n=0}^{\infty} \ a_n(z - z_0)^n \]

This is a Taylor series.  The proof follows, but I will not give it here.

The cofactors are
\[ a_k = \frac{1}{2 \pi i} \int_{\gamma} \frac{f(z)}{(z - z_0)^{k+1}} \ dz = \frac{f^k (z_0)}{k!} \]

\subsection*{example}

The next bit is from HELM:

\url{https://learn.lboro.ac.uk/archive/olmp/olmp_resources/pages/wbooks_fulllist.html}

Taylor series have terms of the form
\[ a_n (x-x_0)^n \] 
where the series is summed over positive integers from $n = 0 \rightarrow \infty$ and the coefficients are
\[ a_n = \frac{f^{(n)}}{n!} \]
the nth derivative of $f$ divided by $n!$

As an example consider
\[ f(x) = \frac{1}{1 - x} \]
This has a singularity at $x = 1$.  We can get the Taylor series expanded around $0$ for this function (this special form is called the Maclaurin series).
\[ f(x) = 1 + x + x^2 + x^3 + \dots \]
We can show that this series is equal to what we started with
\[ \frac{1}{1 - x} = 1 + x + x^2 + x^3 + \dots \]
by multiplying the right-hand side by $(1-x)$.  Imagine two long rows of numbers, one the series itself, and the second containing all the terms of the series multiplied by $-x$.  It's clear that everything cancels except the term $1$.

Alternatively, we can take derivatives and construct the series formally:
\[ f(x) = \frac{1}{1 - x} = (1-x)^{-1} \]
\[ f'(x) = \frac{1}{(1 - x)^2} = (1-x)^{-2} \]
Notice that the minus sign from the exponent cancels the minus sign from the term $(1-x)$ obtained by the chain rule.  
\[ f''(x) = \frac{2}{(1 - x)^3} \]
\[ f'''(x) = \frac{3!}{(1 - x)^4} \]
and so on.

Now, evaluated at $x_0 = 0$, these derivatives are seen to collapse to just the factorial, so we construct the terms of the series as
\[ a_n = \frac{f^{(n)}}{n!} \]
\[ = n! \ \frac{1}{n!} \]
and the factorials also cancel.  This leaves the particularly simple form:
\[ \sum_{n=0}^{\infty} x^n = 1 + x + x^2 + x^3 + \dots \]

\subsection*{convergence}
For most series the big question is:  what is the radius of convergence?

The series expansion for real functions is centered around a fixed point $x_0$ with terms like $(x - x_0)^n$, and the series has a finite sum, only converges for $x$ sufficiently close to $x_0$.

\[ |x - x_0| < r \]

Likewise, for complex functions, series expansions will usually only be valid for a circle (or disk, or region) of convergence in the Argand plane with 
\[ | z - z_0 | < R \]
Convergence can be decided by certain tests including the ratio test and the root test (but sometimes the result is not clear).

Consider whether this complex series converges.  
\[ f(z) = \frac{1}{1 - z} \]
\[ =\sum_{n=0}^{\infty} z^n = 1 + z + z^2 + z^3 + \dots \]

Without doing any tests, we see that this is the geometric series with ratio $z$, which is known to converge when $|z| < 1$.

As the source says:  

"One of the shortcomings of Taylor series is that the circle of convergence is often only a part of the region in which $f(z)$ is analytic.  The Laurent series is an attempt to represent $f(z)$ as a series at as many points as possible. We expand the series around a point of singularity up to, but not including, the singularity itself."

Laurent series involve an annulus, usually called $D$, which is a circle that has an empty small circle in its center, like a slice through a donut.


\end{document}